{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ankur16225/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1001)\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import wave\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from keras import losses, models, optimizers\n",
    "from keras.activations import relu, softmax\n",
    "from keras.callbacks import (EarlyStopping, LearningRateScheduler,\n",
    "                             ModelCheckpoint, TensorBoard, ReduceLROnPlateau)\n",
    "from keras.layers import (Convolution1D, Dense, Dropout, GlobalAveragePooling1D, \n",
    "                          GlobalMaxPool1D, Input, MaxPool1D, concatenate)\n",
    "from keras.utils import Sequence, to_categorical\n",
    "\n",
    "from keras.layers import (Convolution2D, GlobalAveragePooling2D, BatchNormalization, Flatten,\n",
    "                          GlobalMaxPool2D, MaxPool2D, concatenate, Activation)\n",
    "from keras.utils import Sequence, to_categorical\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "test = pd.read_csv(\"../data/test_post_competition.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "      <th>manually_verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00044347.wav</td>\n",
       "      <td>Hi-hat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001ca53d.wav</td>\n",
       "      <td>Saxophone</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002d256b.wav</td>\n",
       "      <td>Trumpet</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0033e230.wav</td>\n",
       "      <td>Glockenspiel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00353774.wav</td>\n",
       "      <td>Cello</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname         label  manually_verified\n",
       "0  00044347.wav        Hi-hat                  0\n",
       "1  001ca53d.wav     Saxophone                  1\n",
       "2  002d256b.wav       Trumpet                  0\n",
       "3  0033e230.wav  Glockenspiel                  1\n",
       "4  00353774.wav         Cello                  1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "      <th>usage</th>\n",
       "      <th>freesound_id</th>\n",
       "      <th>license</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00326aa9.wav</td>\n",
       "      <td>Oboe</td>\n",
       "      <td>Private</td>\n",
       "      <td>355125</td>\n",
       "      <td>Attribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0038a046.wav</td>\n",
       "      <td>Bass_drum</td>\n",
       "      <td>Private</td>\n",
       "      <td>90621</td>\n",
       "      <td>Creative Commons 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>007759c4.wav</td>\n",
       "      <td>Saxophone</td>\n",
       "      <td>Private</td>\n",
       "      <td>13406</td>\n",
       "      <td>Creative Commons 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>008afd93.wav</td>\n",
       "      <td>Saxophone</td>\n",
       "      <td>Private</td>\n",
       "      <td>358962</td>\n",
       "      <td>Attribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00ae03f6.wav</td>\n",
       "      <td>Chime</td>\n",
       "      <td>Private</td>\n",
       "      <td>78203</td>\n",
       "      <td>Attribution</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           fname      label    usage  freesound_id             license\n",
       "4   00326aa9.wav       Oboe  Private        355125         Attribution\n",
       "5   0038a046.wav  Bass_drum  Private         90621  Creative Commons 0\n",
       "8   007759c4.wav  Saxophone  Private         13406  Creative Commons 0\n",
       "9   008afd93.wav  Saxophone  Private        358962         Attribution\n",
       "12  00ae03f6.wav      Chime  Private         78203         Attribution"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove None Label from test data\n",
    "test.drop(test[test.label == 'None'].index, inplace=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Classes:  41\n",
      "No. of Training Samples: 9473, No. of Test Samples: 1600\n"
     ]
    }
   ],
   "source": [
    "print('No. of Classes: ', len(train.label.unique()))\n",
    "print('No. of Training Samples: {}, No. of Test Samples: {}'.format(len(train), len(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "64df4fea-4917-4762-b9be-68163f590c13",
    "_uuid": "927b4d615e24291f3c9510b653e723dc031fd042"
   },
   "source": [
    "#### Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING_RATE = 16_000\n",
    "DURATION = 2\n",
    "CLASSES = 41\n",
    "FOLDS = 10\n",
    "LEARNING_RATE = .001\n",
    "MAX_EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "AUDIO_LENGTH = SAMPLING_RATE * DURATION\n",
    "DIM = (AUDIO_LENGTH,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conv1D Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1d_conv_model():\n",
    "    \n",
    "    inp = Input(shape=(AUDIO_LENGTH,1))\n",
    "    x = Convolution1D(16, 9, activation=relu)(inp)\n",
    "    x = Convolution1D(16, 9, activation=relu)(x)\n",
    "    x = MaxPool1D(16)(x)\n",
    "    x = Dropout(rate=0.1)(x)\n",
    "    \n",
    "    x = Convolution1D(32, 3, activation=relu)(x)\n",
    "    x = Convolution1D(32, 3, activation=relu)(x)\n",
    "    x = MaxPool1D(4)(x)\n",
    "    x = Dropout(rate=0.1)(x)\n",
    "    \n",
    "    x = Convolution1D(32, 3, activation=relu)(x)\n",
    "    x = Convolution1D(32, 3, activation=relu)(x)\n",
    "    x = MaxPool1D(4)(x)\n",
    "    x = Dropout(rate=0.1)(x)\n",
    "    \n",
    "    x = Convolution1D(256, 3, activation=relu)(x)\n",
    "    x = Convolution1D(256, 3, activation=relu)(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "\n",
    "    x = Dense(64, activation=relu)(x)\n",
    "    x = Dense(1028, activation=relu)(x)\n",
    "    out = Dense(CLASSES, activation=softmax)(x)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "    opt = optimizers.Adam(LEARNING_RATE)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils.vis_utils import plot_model\n",
    "# model = get_1d_conv_model()\n",
    "# plot_model(model, to_file='model_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LABELS = list(train.label.unique())\n",
    "label_idx = {label: i for i, label in enumerate(LABELS)}\n",
    "train.set_index(\"fname\", inplace=True)\n",
    "test.set_index(\"fname\", inplace=True)\n",
    "train[\"label_idx\"] = train.label.apply(lambda x: label_idx[x])\n",
    "test[\"label_idx\"] = test.label.apply(lambda x: label_idx[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "5b9b1c9b-7e02-46f3-96f6-67ebc9bf9132",
    "_uuid": "5242e943f1bc1154d19c03c361a826553c811cfe"
   },
   "outputs": [],
   "source": [
    "def prepare_data(df, data_dir):\n",
    "    X = np.empty(shape=(df.shape[0], DIM[0], 1))\n",
    "    input_length = AUDIO_LENGTH\n",
    "    for i, fname in tqdm_notebook(enumerate(df.index)):\n",
    "        file_path = data_dir + fname\n",
    "        data, _ = librosa.core.load(file_path, sr=SAMPLING_RATE, res_type=\"kaiser_fast\")\n",
    "\n",
    "        # Random offset / Padding\n",
    "        if len(data) > input_length:\n",
    "            max_offset = len(data) - input_length\n",
    "            offset = np.random.randint(max_offset)\n",
    "            data = data[offset:(input_length+offset)]\n",
    "        else:\n",
    "            if input_length > len(data):\n",
    "                max_offset = input_length - len(data)\n",
    "                offset = np.random.randint(max_offset)\n",
    "            else:\n",
    "                offset = 0\n",
    "            data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "        data = data[:, np.newaxis]\n",
    "        \n",
    "        X[i,] = data\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "c9910de1-388b-470e-8908-6df548f1b866",
    "_uuid": "bb3bc487b52a549a856807dd838a4f6cd209917d"
   },
   "outputs": [],
   "source": [
    "if not LOAD:\n",
    "    X_train = prepare_data(train, '../data/audio_train/')\n",
    "    X_test = prepare_data(test, '../data/audio_test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "c9910de1-388b-470e-8908-6df548f1b866",
    "_uuid": "bb3bc487b52a549a856807dd838a4f6cd209917d"
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(train.label_idx, num_classes=CLASSES)\n",
    "y_test = to_categorical(test.label_idx, num_classes=CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "928b0993-7799-4b75-bef8-c1df3755632e",
    "_uuid": "60b6d9dfcb25eb9b3cef7e05675d67b104e24b31"
   },
   "outputs": [],
   "source": [
    "# Normalization\n",
    "if not LOAD:\n",
    "    mean = np.mean(X_train, axis=0)\n",
    "    std = np.std(X_train, axis=0)\n",
    "\n",
    "    X_train = (X_train - mean)/std\n",
    "    X_test = (X_test - mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "af8afd09-66bf-4618-ad95-d70db35b90ec",
    "_uuid": "b70fea949114595111c39f9f64fb1752603e3fdf"
   },
   "source": [
    "### Training.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTION_FOLDER = \"predictions\"\n",
    "if not LOAD:\n",
    "    if not os.path.exists(PREDICTION_FOLDER):\n",
    "        os.mkdir(PREDICTION_FOLDER)\n",
    "\n",
    "    if os.path.exists('logs/' + PREDICTION_FOLDER):\n",
    "        shutil.rmtree('logs/' + PREDICTION_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not LOAD:\n",
    "    checkpoint = ModelCheckpoint('best_weights.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "    tb = TensorBoard(log_dir='./logs/' + PREDICTION_FOLDER, write_graph=True)\n",
    "    callbacks_list = [checkpoint, early, tb]\n",
    "\n",
    "    model = get_1d_conv_model()\n",
    "\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), callbacks=callbacks_list, \n",
    "                        batch_size=64, epochs=MAX_EPOCHS)\n",
    "\n",
    "    model.save_weights('weights_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best weights\n",
    "model = get_1d_conv_model()\n",
    "model.load_weights('best_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "10fb7477-8122-49fb-be81-1adb7aa45c7f",
    "_uuid": "ab0f2bc7e7bbaced3eb2e4c3acb7c7c63aa73681"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.84       300\n",
      "           1       0.82      0.64      0.72       300\n",
      "           2       0.90      0.71      0.80       300\n",
      "           3       0.58      0.70      0.63        94\n",
      "           4       0.54      0.63      0.58       300\n",
      "           5       0.79      0.77      0.78       279\n",
      "           6       0.73      0.67      0.70       147\n",
      "           7       0.59      0.69      0.64       300\n",
      "           8       0.65      0.87      0.74       119\n",
      "           9       0.67      0.85      0.75       139\n",
      "          10       0.82      0.87      0.84       300\n",
      "          11       0.80      0.69      0.74       270\n",
      "          12       0.85      0.70      0.77       300\n",
      "          13       0.70      0.82      0.76       300\n",
      "          14       0.93      0.85      0.89       300\n",
      "          15       0.74      0.93      0.82       299\n",
      "          16       0.61      0.59      0.60       300\n",
      "          17       0.90      0.75      0.82       243\n",
      "          18       0.66      0.67      0.66       120\n",
      "          19       0.91      0.72      0.81       239\n",
      "          20       0.59      0.70      0.64       115\n",
      "          21       0.94      0.85      0.90       300\n",
      "          22       0.48      0.73      0.58       109\n",
      "          23       0.68      0.40      0.50       300\n",
      "          24       0.69      0.72      0.70        95\n",
      "          25       0.81      0.62      0.70       165\n",
      "          26       0.50      0.54      0.52       292\n",
      "          27       0.54      0.71      0.61       146\n",
      "          28       0.92      0.90      0.91       210\n",
      "          29       0.75      0.79      0.77       300\n",
      "          30       0.68      0.75      0.71       300\n",
      "          31       0.73      0.64      0.68       300\n",
      "          32       0.93      0.81      0.87       221\n",
      "          33       0.83      0.83      0.83       191\n",
      "          34       0.82      0.53      0.64       150\n",
      "          35       0.81      0.58      0.68       155\n",
      "          36       0.68      0.66      0.67       158\n",
      "          37       0.81      0.94      0.87       300\n",
      "          38       0.42      0.69      0.52       300\n",
      "          39       0.72      0.64      0.68       300\n",
      "          40       0.97      0.79      0.87       117\n",
      "\n",
      "   micro avg       0.73      0.73      0.73      9473\n",
      "   macro avg       0.74      0.73      0.73      9473\n",
      "weighted avg       0.75      0.73      0.73      9473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not LOAD:\n",
    "    # Save train predictions\n",
    "    predictions = model.predict(X_train, batch_size=64, verbose=1)\n",
    "    np.save(PREDICTION_FOLDER + '/train_predictions.npy', predictions)\n",
    "    train_eval = model.evaluate(x=X_train, y=y_train, batch_size=64, verbose=1)\n",
    "    print('Training Accuracy: ', train_eval[1])\n",
    "\n",
    "predictions = np.load(PREDICTION_FOLDER + '/train_predictions.npy')\n",
    "from sklearn.metrics import classification_report\n",
    "print('Train Classification Report:')\n",
    "print(classification_report(np.argmax(y_train, axis=1), np.argmax(predictions, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "10fb7477-8122-49fb-be81-1adb7aa45c7f",
    "_uuid": "ab0f2bc7e7bbaced3eb2e4c3acb7c7c63aa73681"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.69        39\n",
      "           1       0.87      0.65      0.75       110\n",
      "           2       0.75      0.73      0.74        37\n",
      "           3       0.54      0.48      0.51        29\n",
      "           4       0.48      0.52      0.50        54\n",
      "           5       0.72      0.72      0.72        39\n",
      "           6       0.74      0.44      0.55        63\n",
      "           7       0.38      0.66      0.48        56\n",
      "           8       0.57      0.65      0.61        26\n",
      "           9       0.62      0.75      0.68        28\n",
      "          10       0.66      0.85      0.74        34\n",
      "          11       0.67      0.34      0.45        29\n",
      "          12       0.88      0.74      0.80        38\n",
      "          13       0.48      0.93      0.63        27\n",
      "          14       0.76      0.73      0.75        30\n",
      "          15       0.51      0.88      0.64        42\n",
      "          16       0.47      0.42      0.44        55\n",
      "          17       0.73      0.63      0.68        30\n",
      "          18       0.81      0.52      0.63        48\n",
      "          19       0.95      0.68      0.79        28\n",
      "          20       0.57      0.41      0.48        29\n",
      "          21       0.69      0.79      0.73        28\n",
      "          22       0.83      0.60      0.70        25\n",
      "          23       0.30      0.21      0.24        29\n",
      "          24       0.52      0.48      0.50        25\n",
      "          25       0.88      0.42      0.57        33\n",
      "          26       0.29      0.46      0.36        37\n",
      "          27       0.44      0.48      0.46        29\n",
      "          28       0.73      0.94      0.82        32\n",
      "          29       0.71      0.68      0.69        40\n",
      "          30       0.37      0.69      0.48        29\n",
      "          31       0.59      0.41      0.48        32\n",
      "          32       0.84      0.78      0.81        40\n",
      "          33       0.76      0.88      0.81        42\n",
      "          34       0.40      0.19      0.26        32\n",
      "          35       0.65      0.38      0.48        29\n",
      "          36       0.62      0.52      0.57        29\n",
      "          37       0.82      0.97      0.89        32\n",
      "          38       0.27      0.49      0.35        45\n",
      "          39       0.74      0.54      0.62       108\n",
      "          40       0.79      0.67      0.72        33\n",
      "\n",
      "   micro avg       0.61      0.61      0.61      1600\n",
      "   macro avg       0.63      0.61      0.61      1600\n",
      "weighted avg       0.65      0.61      0.61      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not LOAD:\n",
    "    # Save test predictions\n",
    "    predictions = model.predict(X_test, batch_size=64, verbose=1)\n",
    "    np.save(PREDICTION_FOLDER + '/test_predictions.npy', predictions)\n",
    "    test_eval = model.evaluate(x=X_test, y=y_test, batch_size=64, verbose=1)\n",
    "    print('Test Accuracy: ', test_eval[1])\n",
    "\n",
    "predictions = np.load(PREDICTION_FOLDER + '/test_predictions.npy')\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('Test Classification Report:')\n",
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(predictions, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Top3 Accuracy:  0.82875\n"
     ]
    }
   ],
   "source": [
    "# Calculate top3 accuracy\n",
    "test.reset_index(inplace=True)\n",
    "test.drop(['fname', 'usage', 'freesound_id', 'license'], axis=1, inplace=True)\n",
    "top_3 = np.array(LABELS)[np.argsort(-predictions, axis=1)[:, :3]]\n",
    "predicted_labels = [' '.join(list(x)) for x in top_3]\n",
    "test['predicted_label'] = predicted_labels\n",
    "top3_acc = 0.\n",
    "for index, row in test.iterrows():\n",
    "    if row['label'] in row['predicted_label'].split():\n",
    "        top3_acc += 1\n",
    "top3_acc /= len(test)\n",
    "print('Test Top3 Accuracy: ', top3_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
